{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa67366",
   "metadata": {},
   "source": [
    "# Two towers approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d595c",
   "metadata": {},
   "source": [
    "The Two-Towers Neural Network is a deep learning-based approach used for recommendation systems. It leverages a neural network architecture with two distinct input \"towers\": one for users and one for items. Each tower processes its respective input (user and item embeddings) through shared or separate neural layers, ultimately learning to predict user-item interactions.\n",
    "\n",
    "This approach is particularly powerful for large-scale recommendation systems as it can learn complex, non-linear relationships between users and items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089cd19",
   "metadata": {},
   "source": [
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f1279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA_FOLDER=\"../data\"\n",
    "if [ ! -d \"$DATA_FOLDER\" ]; then\n",
    "    wget --no-check-certificate \"https://drive.usercontent.google.com/download?id=1qe5hOSBxzIuxBb1G_Ih5X-O65QElollE&export=download&confirm=t&uuid=b2002093-cc6e-4bd5-be47-9603f0b33470\" -O KuaiRec.zip\n",
    "    unzip KuaiRec.zip -d \"$DATA_FOLDER\"\n",
    "    rm KuaiRec.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be69cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.api.layers import Concatenate, Dense, Dropout, Input\n",
    "from keras.api.models import Model\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.saving import load_model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde2fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets.\n",
    "data = \"../data/KuaiRec 2.0/data\"\n",
    "interactions = pd.read_csv(f\"{data}/big_matrix.csv\")\n",
    "categories = pd.read_csv(f\"{data}/item_categories.csv\")\n",
    "user_features = pd.read_csv(f\"{data}/user_features.csv\")\n",
    "item_features = pd.read_csv(f\"{data}/item_daily_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558db362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless data.\n",
    "interactions = interactions.dropna()\n",
    "interactions = interactions.drop_duplicates()\n",
    "interactions = interactions[interactions[\"timestamp\"] >= 0]\n",
    "\n",
    "# Drop useless data.\n",
    "user_features = user_features[[\"user_active_degree\", \"follow_user_num\"] + [f\"onehot_feat{x}\" for x in range(18)]]\n",
    "user_features.fillna(-1, inplace=True)\n",
    "\n",
    "# Aggregate days.\n",
    "item_features = item_features_agg = item_features.groupby(\"video_id\").agg({\n",
    "    \"play_cnt\": \"sum\",\n",
    "    \"share_cnt\": \"sum\",\n",
    "    \"download_cnt\": \"sum\",\n",
    "    \"comment_cnt\": \"sum\",\n",
    "    \"upload_type\": \"first\",\n",
    "    \"author_id\": \"first\",\n",
    "    \"video_duration\": \"first\"\n",
    "})\n",
    "item_features[\"video_duration\"] = item_features[\"video_duration\"].fillna(item_features[\"video_duration\"].median())\n",
    "# Drop usless data.\n",
    "item_features = item_features.dropna()\n",
    "item_features = item_features.drop_duplicates()\n",
    "\n",
    "# Drop useless data.\n",
    "categories = categories.dropna()\n",
    "categories = categories.drop_duplicates()\n",
    "# Convert the feat column from a string representation of an array into an array.\n",
    "categories[\"feat\"] = categories[\"feat\"].apply(lambda x: json.loads(x))\n",
    "all_categories = set(cat for sublist in categories[\"feat\"] for cat in sublist)\n",
    "# Convert multi-label categories to binary columns.\n",
    "for cat in all_categories:\n",
    "    item_features[f'cat_{cat}'] = categories[\"feat\"].apply(lambda x: int(cat in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0e83c",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07332f8a",
   "metadata": {},
   "source": [
    "### Preparing the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15556457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels of string columns.\n",
    "item_features[\"upload_type\"] = LabelEncoder().fit_transform(item_features[\"upload_type\"])\n",
    "user_features[\"user_active_degree\"] = LabelEncoder().fit_transform(user_features[\"user_active_degree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644a7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "user_features = StandardScaler().fit_transform(user_features)\n",
    "item_features = StandardScaler().fit_transform(item_features)\n",
    "watch_ratios = StandardScaler().fit_transform(interactions[[\"watch_ratio\"]].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8416d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test.\n",
    "\n",
    "user_features_train = user_features[interactions[\"user_id\"]]\n",
    "item_features_train = item_features[interactions[\"video_id\"]]\n",
    "y_train = watch_ratios\n",
    "\n",
    "# Load the test df.\n",
    "test_df = pd.read_csv(f\"{data}/small_matrix.csv\")\n",
    "test_df = test_df.dropna()\n",
    "test_df = test_df.drop_duplicates()\n",
    "test_df = test_df[test_df[\"timestamp\"] >= 0]\n",
    "\n",
    "user_features_test = user_features[test_df[\"user_id\"]]\n",
    "item_features_test = item_features[test_df[\"video_id\"]]\n",
    "y_test = StandardScaler().fit_transform(test_df[[\"watch_ratio\"]].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464e1c9",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db7c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = user_features_train.shape[1]\n",
    "n_videos = item_features_train.shape[1]\n",
    "\n",
    "input_user = Input(shape=(n_users,))\n",
    "input_video = Input(shape=(n_videos,))\n",
    "\n",
    "combined = Concatenate()([input_user, input_video])\n",
    "x = Dense(128, activation=\"relu\")(combined)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[input_user, input_video], outputs=output)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45dcf5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4f0e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m90352/90352\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1ms/step - loss: 0.9465 - mae: 0.3329 - val_loss: 0.9359 - val_mae: 0.2884 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m90352/90352\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1ms/step - loss: 0.9274 - mae: 0.3236 - val_loss: 0.9324 - val_mae: 0.2885 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m90352/90352\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1ms/step - loss: 0.9539 - mae: 0.3235 - val_loss: 0.9327 - val_mae: 0.2888 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m90320/90352\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.9153 - mae: 0.3224\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m90352/90352\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1ms/step - loss: 0.9153 - mae: 0.3224 - val_loss: 0.9339 - val_mae: 0.2902 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m90352/90352\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1ms/step - loss: 0.9596 - mae: 0.3220 - val_loss: 0.9347 - val_mae: 0.2934 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=[user_features_train, item_features_train],\n",
    "    y=y_train,\n",
    "    validation_data=([user_features_test, item_features_test], y_test),\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")\n",
    "\n",
    "model.save(\"two-towers.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b854687",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b65efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140456/140456\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 342us/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"two-towers.keras\")\n",
    "\n",
    "inverse_scaler = StandardScaler().fit(interactions[[\"watch_ratio\"]].values)\n",
    "\n",
    "y_true = inverse_scaler.inverse_transform(y_test).flatten()\n",
    "\n",
    "predictions = model.predict([user_features_test, item_features_test])\n",
    "y_pred = inverse_scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d68425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Model Evaluation Metrics:\n",
      "â¡ï¸  MAE  (Mean Absolute Error)    : 0.4844\n",
      "â¡ï¸  RMSE (Root Mean Squared Error): 1.6211\n",
      "â¡ï¸  RÂ² Score                      : 0.0676\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"ğŸ“Š Model Evaluation Metrics:\")\n",
    "print(f\"â¡ï¸  MAE  (Mean Absolute Error)    : {round(mae, 4)}\")\n",
    "print(f\"â¡ï¸  RMSE (Root Mean Squared Error): {round(rmse, 4)}\")\n",
    "print(f\"â¡ï¸  RÂ² Score                      : {round(r2, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba4ac3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we implemented and evaluated a **Two Towers Neural Network** for collaborative filtering. This architecture uses two separate neural networks to process user and item data, respectively, and then combines their outputs to make predictions.\n",
    "\n",
    "### Insights from the Evaluation:\n",
    "- **MAE**: The **Mean Absolute Error** of **0.4844** indicates that, on average, the predicted ratings differ from the actual ratings by about 0.48. This shows a moderate level of prediction accuracy, with room for further improvement.\n",
    "\n",
    "- **RMSE**: The **Root Mean Squared Error** of **1.6211** suggests there is some variability between the predicted and actual ratings, although slightly better than the previous result. This indicates the model reduces larger errors somewhat but could still be optimized further.\n",
    "\n",
    "- **RÂ² Score**: The **RÂ² Score** of **0.0676** implies that the model explains about **6.6%** of the variance in the actual ratings. While slightly improved, this low value still points to potential underfitting and the need for better representation of the dataâ€™s underlying patterns.\n",
    "\n",
    "The **Two Towers Neural Network** model demonstrates **moderate performance** based on the evaluation metrics. While the **MAE** shows reasonably close predictions, the **RMSE** and particularly the **RÂ² Score** suggest that the model struggles to fully capture the complexity and variance in the data.\n",
    "\n",
    "To enhance the modelâ€™s performance, the following steps may be considered:\n",
    "- Further **hyperparameter tuning** (e.g., learning rate, number of layers, neurons per layer)\n",
    "- Applying **regularization techniques** to reduce overfitting\n",
    "- Introducing **advanced architectures**, such as attention mechanisms\n",
    "- Exploring **hybrid recommender systems** that combine collaborative and content-based features\n",
    "\n",
    "Overall, the **Two Towers architecture** provides a solid baseline for collaborative filtering, but there is significant room for optimization to improve both accuracy and generalization. Continued experimentation with more complex models and refined training strategies could lead to better recommendation outcomes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
